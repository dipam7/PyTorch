{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "PyTorch has a module `nn` that provides a nice way to efficiently build large neural networks. We will be using the MNIST handwritten digit dataset, which comes in the form of `28 * 28` pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:00, 27157044.36it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 278960.78it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 5865805.26it/s]                          \n",
      "8192it [00:00, 101004.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader turns our data into an iterator and then we can use `iter(trainloader)` to call the next batch of data. We can also use a loop for the same as \n",
    "\n",
    "for image, label in trainloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 - no of images\n",
    "# 1 - no of channels (gray scale only)\n",
    "# 28 * 28 pixels = shape of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98889a6cc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADWxJREFUeJzt3X2IVXUex/HPNx+SSiI3ViRntzZKECvbhtpAFqOSNiotood/MhAneoDtiQqXWqMaYumB+qcY0bRwdRfM8o/ISjZsabG02h5stQe0RnSmMqiIaG2++8cc26nm/s507rn3nPH7fsEw957vPed8uc7Hc+793Xt+5u4CEM9BVTcAoBqEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUGPbuTMz4+OEQIu5u43kcU0d+c3sHDPbZmbvm9ltzWwLQHtZ0c/2m9kYSdslnS2pV9Krki53962JdTjyAy3WjiP/qZLed/cP3f1bSaslzW1iewDaqJnwHyXp4yH3e7NlP2BmXWa22cw2N7EvACVr+Rt+7t4jqUfitB+ok2aO/LskdQy5PzVbBmAUaCb8r0o6zsyOMbPxki6TtK6ctgC0WuHTfnffZ2bXSVovaYykZe7+TmmdAWipwkN9hXbGa36g5dryIR8AoxfhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRWeoluSzGyHpC8lfSdpn7t3ltEUgNZrKvyZM9z90xK2A6CNOO0Hgmo2/C7pOTPbYmZdZTQEoD2aPe2f5e67zOyXkp43s/+4+8ahD8j+U+A/BqBmzN3L2ZDZYklfuft9iceUszMADbm7jeRxhU/7zexQM5u4/7akOZLeLro9AO3VzGn/ZElrzWz/dv7q7s+W0hWAlivttH9EO+O0v+3OP//8ZP2UU05J1k877bRkfePGjcl6M3p6epL1zz77rGX7Hs1aftoPYHQj/EBQhB8IivADQRF+ICjCDwTFUF8NdHR0JOvXXHNN4fqECROS644d29wnvA86KH38GBgYKLztr7/+uqltL126tGFty5YtyXVXrlyZrNcZQ30Akgg/EBThB4Ii/EBQhB8IivADQRF+ICjG+WvgrLPOStbXr19feNt5Y+VXXHFFsr5p06Zkvbu7O1lP/X1dfPHFyXUPOeSQZL0Z+/btS9b7+/uT9dtvvz1ZX758+c9tqTSM8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiBoMqYpRc1dscddyTra9eubWr7V155ZeF177nnnmR9zJgxhbctSQsWLGhY++CDD5LrzpkzJ1nv6+sr1FOdcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByv89vZssknSep391nZMsmSfqbpKMl7ZB0ibt/nrszvs8/rDVr1iTr8+bNK7ztvHH4J554ovC2UU9lfp9/uaRzfrTsNkkb3P04SRuy+wBGkdzwu/tGSXt/tHiupBXZ7RWSih+aAFSi6Gv+ye6+O7u9R9LkkvoB0CZNf7bf3T31Wt7MuiR1NbsfAOUqeuTvM7MpkpT9bni1Q3fvcfdOd+8suC8ALVA0/Oskzc9uz5f0dDntAGiX3PCb2SpJ/5I0zcx6zWyBpHslnW1m70k6K7sPYBTJfc3v7pc3KJ1Zci8HrEmTJiXrxx9/fFPbf/nllxvWXnjhhaa2jQMXn/ADgiL8QFCEHwiK8ANBEX4gKMIPBMWlu9sgbyrq6dOnN7X91atXN6wdfvjhyXUvvfTSZP3ZZ58t1NN+27dvb1gbGBhoattoDkd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgq99Ldpe4s6KW7t27dmqxPmzatTZ2Uzyx9lehVq1Y1rC1atCi57s6dOwv1FF2Zl+4GcAAi/EBQhB8IivADQRF+ICjCDwRF+IGgGOdvg9dffz1ZP/HEE9vUSfnyxvlTf1/btm1LrnvGGWck6319fcl6VIzzA0gi/EBQhB8IivADQRF+ICjCDwRF+IGgcsf5zWyZpPMk9bv7jGzZYkkLJX2SPWyRuz+Tu7Og4/x5U3BfdNFFbeqkfN3d3cl6M58jueGGG5L1hx9+uPC2D2RljvMvl3TOMMsfdPeZ2U9u8AHUS2743X2jpL1t6AVAGzXzmv86M3vTzJaZ2RGldQSgLYqG/xFJx0qaKWm3pPsbPdDMusxss5ltLrgvAC1QKPzu3ufu37n7gKQlkk5NPLbH3TvdvbNokwDKVyj8ZjZlyN0LJb1dTjsA2iV3im4zWyVptqQjzaxX0p8lzTazmZJc0g5JV7WwRwAtwPf50ZTZs2cn6+vXr29YGzduXHLdp556KlkfzZ+PaCW+zw8gifADQRF+ICjCDwRF+IGgCD8QVO44P5Dy4osvJuvffPNNw9rYsek/v3YOQ0fEkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcH02ZMWNGsp73tV1UhyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOD+acuuttybrBx98cMPaRx99lFz3lVdeKdQTRoYjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ElTtFt5l1SHpc0mRJLqnH3R8ys0mS/ibpaEk7JF3i7p/nbIsLsddM3rXzu7u7k/Wbb745WU/9fZ1++unJdRnnL6bMKbr3SbrJ3adL+p2ka81suqTbJG1w9+MkbcjuAxglcsPv7rvd/bXs9peS3pV0lKS5klZkD1shaV6rmgRQvp/1mt/MjpZ0sqRNkia7++6stEeDLwsAjBIj/my/mR0maY2k6939C7P/v6xwd2/0et7MuiR1NdsogHKN6MhvZuM0GPyV7v5ktrjPzKZk9SmS+odb19173L3T3TvLaBhAOXLDb4OH+KWS3nX3B4aU1kman92eL+np8tsD0CojGeqbJeklSW9JGsgWL9Lg6/6/S/qVpJ0aHOrbm7MthvrabPz48cn6nXfemazfcsstyfrQl3/D2bNnT8PaSSedlFz3k08+SdYxvJEO9eW+5nf3f0pqtLEzf05TAOqDT/gBQRF+ICjCDwRF+IGgCD8QFOEHguLS3QeAqVOnNqxdffXVyXXzxvHzPProo4XrjONXiyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwSV+33+UnfG9/mHNWHChGR95syZyfrq1asb1jo6OpLr5v37P/bYY8n6woULk3W0X5mX7gZwACL8QFCEHwiK8ANBEX4gKMIPBEX4gaD4Pv8Ipa5/nzdOf+ONNybredevv+CCC5L1gYGBhrVdu3Yl173rrruS9SVLliTrGL048gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAULnj/GbWIelxSZMluaQed3/IzBZLWihp/8XXF7n7M61qtGonnHBCw9qGDRuS606cOLGpfff29ibrd999d8Ma4/RoZCQf8tkn6SZ3f83MJkraYmbPZ7UH3f2+1rUHoFVyw+/uuyXtzm5/aWbvSjqq1Y0BaK2f9ZrfzI6WdLKkTdmi68zsTTNbZmZHNFiny8w2m9nmpjoFUKoRh9/MDpO0RtL17v6FpEckHStppgbPDO4fbj1373H3TnfvLKFfACUZUfjNbJwGg7/S3Z+UJHfvc/fv3H1A0hJJp7auTQBlyw2/mZmkpZLedfcHhiyfMuRhF0p6u/z2ALRK7qW7zWyWpJckvSVp/3dHF0m6XIOn/C5ph6SrsjcHU9vi0t1Ai4300t1ctx84wHDdfgBJhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaDaPUX3p5J2Drl/ZLasjuraW137kuitqDJ7+/VIH9jW7/P/ZOdmm+t6bb+69lbXviR6K6qq3jjtB4Ii/EBQVYe/p+L9p9S1t7r2JdFbUZX0VulrfgDVqfrID6AilYTfzM4xs21m9r6Z3VZFD42Y2Q4ze8vM3qh6irFsGrR+M3t7yLJJZva8mb2X/R52mrSKeltsZruy5+4NMzu3ot46zOwfZrbVzN4xsz9myyt97hJ9VfK8tf2038zGSNou6WxJvZJelXS5u29tayMNmNkOSZ3uXvmYsJn9XtJXkh539xnZsr9I2uvu92b/cR7h7rfWpLfFkr6qeubmbEKZKUNnlpY0T9KVqvC5S/R1iSp43qo48p8q6X13/9Ddv5W0WtLcCvqoPXffKGnvjxbPlbQiu71Cg388bdegt1pw993u/lp2+0tJ+2eWrvS5S/RViSrCf5Skj4fc71W9pvx2Sc+Z2RYz66q6mWFMHjIz0h5Jk6tsZhi5Mze3049mlq7Nc1dkxuuy8YbfT81y999K+oOka7PT21rywddsdRquGdHMze0yzMzS36vyuSs643XZqgj/LkkdQ+5PzZbVgrvvyn73S1qr+s0+3Ld/ktTsd3/F/XyvTjM3DzeztGrw3NVpxusqwv+qpOPM7BgzGy/pMknrKujjJ8zs0OyNGJnZoZLmqH6zD6+TND+7PV/S0xX28gN1mbm50czSqvi5q92M1+7e9h9J52rwHf8PJP2pih4a9PUbSf/Oft6pujdJqzR4GvhfDb43skDSLyRtkPSepBckTapRb09ocDbnNzUYtCkV9TZLg6f0b0p6I/s5t+rnLtFXJc8bn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0PEiRsmfGb9n0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_hidden = 256\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn(n_inputs, n_hidden)\n",
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = torch.randn(n_hidden, n_output)\n",
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1 = torch.randn(n_hidden)\n",
    "B1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2 = torch.randn(n_output)\n",
    "B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = activation(torch.mm(images, W1) + B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = torch.mm(h, W2) + B2\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim = 1 is for the sum of every row\n",
    "# TODO: understand the view function well\n",
    "def softmax(x):\n",
    "    x = torch.exp(x)\n",
    "    exp_sums = torch.sum(x, dim = 1).view(-1,1)\n",
    "    return  x / exp_sums\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = softmax(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3496e-11, 8.1244e-11, 1.1178e-08, 5.9048e-03, 9.5720e-01, 4.6119e-07,\n",
       "         2.4283e-08, 1.9378e-09, 2.8456e-02, 8.4357e-03],\n",
       "        [5.4131e-14, 2.6512e-12, 7.9556e-07, 6.9272e-07, 8.9618e-01, 3.3804e-07,\n",
       "         9.0165e-15, 1.6332e-10, 9.4013e-09, 1.0382e-01],\n",
       "        [8.3075e-15, 1.7572e-14, 1.2813e-10, 9.8018e-01, 1.8160e-11, 4.9070e-09,\n",
       "         3.2599e-13, 2.2629e-13, 1.5865e-09, 1.9821e-02],\n",
       "        [2.8522e-12, 1.3559e-10, 1.9819e-01, 1.6367e-02, 5.5684e-06, 8.2852e-04,\n",
       "         5.5358e-09, 5.9063e-07, 6.0172e-01, 1.8289e-01],\n",
       "        [1.1794e-11, 1.6927e-14, 9.6698e-12, 5.8408e-01, 3.0206e-02, 2.5765e-08,\n",
       "         1.7489e-06, 2.1465e-07, 3.0207e-04, 3.8541e-01],\n",
       "        [4.5371e-11, 7.8617e-12, 1.4348e-07, 2.0355e-07, 1.1946e-02, 6.1722e-03,\n",
       "         5.2901e-12, 4.9063e-05, 7.5266e-02, 9.0657e-01],\n",
       "        [6.8089e-12, 1.2483e-14, 3.8417e-09, 3.6213e-07, 1.5297e-05, 1.6258e-08,\n",
       "         4.9884e-14, 4.7975e-11, 5.2238e-06, 9.9998e-01],\n",
       "        [1.9403e-13, 8.7119e-15, 9.8378e-10, 1.5677e-03, 2.5393e-08, 2.9879e-10,\n",
       "         4.3829e-14, 6.9790e-11, 8.1419e-10, 9.9843e-01],\n",
       "        [1.0116e-15, 1.7053e-12, 2.1642e-08, 1.1232e-02, 1.2013e-02, 6.7128e-13,\n",
       "         1.4295e-09, 7.0324e-08, 1.0609e-04, 9.7665e-01],\n",
       "        [1.4394e-18, 5.8712e-13, 6.4067e-10, 1.3614e-07, 2.2156e-08, 1.4584e-07,\n",
       "         1.4267e-12, 3.3366e-11, 8.3776e-08, 1.0000e+00],\n",
       "        [6.3705e-07, 3.3716e-11, 3.9230e-04, 1.3667e-02, 4.7236e-06, 1.2578e-06,\n",
       "         1.9869e-04, 2.4344e-06, 9.8459e-06, 9.8572e-01],\n",
       "        [8.0340e-15, 6.5402e-12, 1.1748e-08, 6.1896e-05, 2.0734e-03, 1.9114e-09,\n",
       "         1.6123e-06, 8.8175e-12, 2.4196e-05, 9.9784e-01],\n",
       "        [1.5537e-17, 4.5543e-20, 5.3495e-18, 3.2261e-09, 2.6575e-11, 7.3754e-10,\n",
       "         1.2150e-17, 1.0575e-18, 4.8987e-14, 1.0000e+00],\n",
       "        [1.1212e-12, 1.1996e-09, 3.8889e-08, 9.9678e-01, 8.5740e-05, 9.7891e-08,\n",
       "         3.8185e-06, 5.5433e-08, 4.7451e-05, 3.0853e-03],\n",
       "        [7.4283e-16, 5.5408e-16, 1.8203e-08, 1.4555e-02, 5.8221e-07, 9.5168e-10,\n",
       "         7.7653e-12, 8.1227e-09, 5.1874e-05, 9.8539e-01],\n",
       "        [7.5029e-15, 4.5967e-13, 1.4363e-04, 1.7706e-03, 6.0954e-09, 1.6548e-10,\n",
       "         1.8566e-09, 1.6722e-07, 3.2670e-07, 9.9809e-01],\n",
       "        [2.0755e-17, 2.1785e-17, 1.3739e-09, 1.1487e-04, 1.5533e-08, 2.8026e-10,\n",
       "         8.1827e-17, 4.2762e-13, 1.6898e-07, 9.9988e-01],\n",
       "        [1.4541e-13, 4.6212e-12, 2.0552e-04, 6.9469e-04, 8.8432e-01, 1.6092e-06,\n",
       "         3.0622e-09, 1.9122e-07, 6.6018e-03, 1.0818e-01],\n",
       "        [2.5657e-16, 3.0737e-11, 2.0601e-06, 2.2945e-05, 7.3830e-02, 3.1805e-03,\n",
       "         2.6389e-06, 2.9066e-10, 3.0193e-03, 9.1994e-01],\n",
       "        [4.7281e-15, 1.8906e-15, 1.9667e-08, 2.5093e-05, 4.2813e-08, 2.1861e-07,\n",
       "         7.9494e-11, 1.2671e-09, 3.7902e-08, 9.9997e-01],\n",
       "        [4.7079e-11, 1.8936e-16, 7.0371e-11, 2.0059e-02, 3.0312e-04, 2.7164e-05,\n",
       "         4.9444e-09, 4.8146e-10, 9.7830e-01, 1.3062e-03],\n",
       "        [8.1703e-11, 1.1386e-13, 9.7876e-09, 3.6269e-05, 1.1928e-02, 7.2693e-09,\n",
       "         2.5925e-12, 2.3523e-06, 3.3623e-02, 9.5441e-01],\n",
       "        [1.0339e-14, 2.3240e-14, 9.4501e-11, 7.6982e-01, 1.7228e-04, 2.4918e-10,\n",
       "         7.7768e-13, 4.1275e-11, 5.5158e-06, 2.3000e-01],\n",
       "        [1.1628e-12, 2.4559e-11, 1.2084e-07, 4.5756e-06, 4.0614e-05, 2.4906e-05,\n",
       "         8.3431e-06, 1.2607e-11, 3.6991e-06, 9.9992e-01],\n",
       "        [2.4062e-14, 6.2635e-14, 9.9801e-09, 7.3147e-02, 3.9681e-01, 7.4918e-05,\n",
       "         8.9230e-10, 3.7445e-10, 2.3800e-04, 5.2973e-01],\n",
       "        [2.3260e-17, 4.4942e-20, 1.1451e-09, 6.4334e-11, 5.4038e-13, 3.2939e-09,\n",
       "         3.4523e-14, 6.4407e-18, 5.9903e-12, 1.0000e+00],\n",
       "        [2.4574e-14, 1.0893e-11, 7.3605e-08, 1.9664e-09, 8.9805e-06, 4.9325e-03,\n",
       "         1.7218e-10, 4.7943e-06, 9.6904e-01, 2.6017e-02],\n",
       "        [4.2327e-09, 9.4096e-13, 4.7803e-05, 9.9815e-01, 6.8642e-05, 1.0715e-06,\n",
       "         9.3626e-05, 4.5330e-05, 7.3516e-04, 8.6022e-04],\n",
       "        [5.4545e-11, 6.4146e-15, 2.2545e-15, 1.8365e-07, 4.8372e-07, 1.7949e-13,\n",
       "         6.7582e-10, 2.5311e-11, 4.0414e-09, 1.0000e+00],\n",
       "        [8.6281e-13, 3.4567e-16, 8.5516e-06, 9.4907e-03, 1.0259e-04, 7.8170e-11,\n",
       "         5.4660e-10, 4.9068e-09, 1.8208e-08, 9.9040e-01],\n",
       "        [1.8925e-11, 6.9631e-12, 1.9344e-07, 3.3897e-08, 2.5236e-02, 5.7827e-05,\n",
       "         1.1644e-09, 2.2358e-06, 3.7427e-06, 9.7470e-01],\n",
       "        [1.0318e-12, 9.8775e-12, 3.1317e-08, 2.3164e-02, 2.6768e-05, 7.1115e-05,\n",
       "         1.0905e-06, 4.3172e-05, 1.6889e-02, 9.5981e-01],\n",
       "        [4.3572e-11, 3.4857e-08, 9.2266e-07, 5.3101e-03, 7.2908e-01, 1.0539e-04,\n",
       "         2.0668e-07, 7.2245e-05, 6.1976e-02, 2.0345e-01],\n",
       "        [2.3450e-14, 3.1348e-08, 1.1649e-08, 4.4560e-02, 9.7485e-05, 2.2915e-07,\n",
       "         1.5456e-07, 3.0937e-08, 2.0972e-04, 9.5513e-01],\n",
       "        [4.1176e-18, 1.7327e-14, 2.3916e-10, 2.8728e-04, 2.1199e-06, 6.2580e-07,\n",
       "         5.2272e-19, 3.6709e-15, 1.1555e-09, 9.9971e-01],\n",
       "        [1.0322e-08, 2.4446e-15, 2.0716e-04, 6.9909e-03, 1.1408e-07, 4.5883e-11,\n",
       "         5.6088e-08, 1.4923e-07, 1.3338e-06, 9.9280e-01],\n",
       "        [1.4950e-17, 5.6769e-14, 2.9254e-11, 6.7742e-05, 3.1888e-02, 1.4459e-05,\n",
       "         1.6566e-13, 4.2459e-13, 8.0755e-06, 9.6802e-01],\n",
       "        [3.1793e-11, 7.1976e-15, 1.3377e-05, 4.0090e-06, 7.1298e-06, 5.2149e-10,\n",
       "         6.5389e-11, 2.0601e-08, 2.2101e-07, 9.9998e-01],\n",
       "        [1.0577e-16, 1.0681e-11, 3.6314e-04, 8.0358e-03, 1.9494e-06, 3.7300e-07,\n",
       "         2.7369e-08, 1.2223e-13, 4.6260e-06, 9.9159e-01],\n",
       "        [5.1076e-10, 5.5535e-09, 2.9351e-07, 6.9709e-03, 3.8390e-04, 2.4596e-11,\n",
       "         5.1619e-11, 5.0137e-12, 4.9730e-07, 9.9264e-01],\n",
       "        [3.1123e-18, 3.0142e-15, 6.1015e-12, 9.8378e-01, 6.5623e-10, 5.2481e-08,\n",
       "         4.5576e-11, 2.1613e-12, 8.5987e-10, 1.6219e-02],\n",
       "        [8.0539e-14, 1.3771e-14, 2.3816e-12, 1.0924e-06, 6.0780e-09, 1.0592e-12,\n",
       "         5.0686e-12, 2.3115e-14, 8.2940e-09, 1.0000e+00],\n",
       "        [8.7793e-22, 5.7703e-19, 3.0074e-09, 1.2078e-11, 6.4440e-13, 4.4612e-13,\n",
       "         1.8563e-13, 5.3768e-18, 9.8101e-13, 1.0000e+00],\n",
       "        [7.2774e-19, 5.4397e-18, 3.7074e-08, 1.0178e-09, 3.5645e-07, 6.2267e-10,\n",
       "         1.1150e-12, 7.6240e-14, 8.6162e-08, 1.0000e+00],\n",
       "        [3.9554e-17, 2.2618e-18, 5.4890e-09, 6.0006e-08, 1.0639e-06, 7.6810e-08,\n",
       "         3.2351e-13, 1.2508e-12, 6.1722e-11, 1.0000e+00],\n",
       "        [4.3754e-15, 6.0995e-18, 3.1733e-10, 8.9495e-04, 4.3360e-07, 3.8224e-07,\n",
       "         1.2738e-14, 3.4055e-07, 2.1378e-07, 9.9910e-01],\n",
       "        [4.0205e-14, 8.6611e-14, 8.5206e-08, 1.1176e-02, 3.2938e-04, 9.6401e-08,\n",
       "         1.4118e-11, 5.5440e-07, 1.7155e-06, 9.8849e-01],\n",
       "        [2.7878e-12, 8.6563e-12, 2.8397e-07, 6.9486e-05, 9.6745e-06, 3.7660e-06,\n",
       "         3.9376e-11, 3.7948e-09, 7.8907e-05, 9.9984e-01],\n",
       "        [9.7406e-17, 2.8661e-15, 2.4007e-09, 2.9469e-01, 6.3246e-08, 2.2996e-06,\n",
       "         4.7961e-11, 8.4820e-11, 2.4369e-08, 7.0530e-01],\n",
       "        [5.6327e-14, 1.5022e-16, 3.5164e-11, 4.0215e-02, 1.7675e-06, 2.7976e-07,\n",
       "         1.8317e-10, 8.7500e-08, 4.0304e-05, 9.5974e-01],\n",
       "        [6.0056e-12, 9.7494e-11, 6.6786e-06, 1.6153e-02, 3.1065e-04, 8.2309e-06,\n",
       "         4.5637e-04, 6.1285e-09, 5.6945e-08, 9.8306e-01],\n",
       "        [2.7156e-18, 4.9972e-15, 9.8385e-11, 5.1170e-11, 1.8236e-07, 8.8910e-12,\n",
       "         2.8463e-11, 1.5388e-12, 1.1261e-08, 1.0000e+00],\n",
       "        [1.5411e-15, 1.4367e-13, 5.2928e-01, 3.9469e-02, 5.3061e-02, 5.7503e-10,\n",
       "         4.6488e-11, 1.4639e-07, 3.2657e-09, 3.7819e-01],\n",
       "        [2.2841e-17, 1.6522e-16, 9.9746e-09, 5.3276e-09, 3.6666e-03, 1.2357e-06,\n",
       "         9.0211e-13, 7.7860e-11, 1.4467e-04, 9.9619e-01],\n",
       "        [1.3485e-16, 3.2279e-11, 4.8260e-09, 4.6439e-08, 1.9777e-04, 3.8069e-11,\n",
       "         2.3139e-10, 4.6977e-08, 8.9881e-09, 9.9980e-01],\n",
       "        [9.6550e-12, 2.1733e-13, 1.8478e-11, 2.2369e-03, 1.6116e-04, 3.2766e-07,\n",
       "         4.2267e-07, 1.2163e-07, 1.1775e-05, 9.9759e-01],\n",
       "        [6.1260e-13, 2.2410e-12, 1.9096e-06, 1.1654e-01, 3.0468e-06, 7.4697e-12,\n",
       "         1.7246e-06, 1.4605e-10, 3.9235e-06, 8.8345e-01],\n",
       "        [6.5196e-13, 8.3651e-11, 2.4716e-09, 9.8942e-01, 2.0104e-08, 1.2920e-11,\n",
       "         2.2946e-15, 3.0251e-07, 3.2873e-07, 1.0584e-02],\n",
       "        [4.6798e-15, 1.5769e-13, 3.3109e-06, 1.2595e-05, 7.2721e-07, 2.8797e-09,\n",
       "         2.7164e-15, 1.4900e-09, 2.2680e-07, 9.9998e-01],\n",
       "        [6.5783e-15, 1.2045e-14, 6.6839e-08, 5.0715e-03, 9.8088e-04, 3.9842e-06,\n",
       "         6.8571e-06, 2.2190e-03, 5.2708e-03, 9.8645e-01],\n",
       "        [1.4548e-15, 4.0037e-16, 3.2712e-08, 8.3612e-09, 7.9575e-09, 5.8690e-11,\n",
       "         2.2336e-12, 2.3919e-10, 1.2471e-09, 1.0000e+00],\n",
       "        [6.8432e-15, 1.3968e-10, 1.1804e-09, 3.4428e-01, 7.9636e-04, 2.3037e-04,\n",
       "         1.2926e-15, 4.2417e-06, 3.6161e-04, 6.5432e-01],\n",
       "        [2.5168e-11, 1.1174e-14, 1.4341e-06, 1.1072e-02, 6.4280e-07, 1.6136e-06,\n",
       "         8.4791e-12, 4.9090e-03, 3.3840e-06, 9.8401e-01],\n",
       "        [9.4153e-17, 2.1908e-13, 1.6242e-11, 1.0934e-07, 5.0762e-04, 9.0024e-06,\n",
       "         3.5574e-14, 2.2026e-16, 3.7796e-09, 9.9948e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.sum(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNetwork(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnotherNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do this is because we can keep softmax and sigmoid purely functional without\n",
    "# creating any objects or classes or instances for them\n",
    "# both the implementations are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_1 = nn.Linear(784, 128)\n",
    "        self.hidden_2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        x = F.relu(self.hidden_2(x))\n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewNetwork(\n",
       "  (hidden_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NewNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
