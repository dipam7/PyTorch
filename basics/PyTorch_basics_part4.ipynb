{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST\n",
    "\n",
    "Since MNIST is a relatively easy dataset these days we will work on fashion MNIST. It's a relatively hard problem compared to MNIST and will give us a good idea about how our model is performing. It is also a better representation of real world datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:01, 14226004.31it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 99260.92it/s]            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:01, 4297032.26it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 37908.42it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "plt.imshow(image[1,:].reshape((28,28)), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(784, 256),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(256, 128),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(128, 64),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(64, 10),\n",
    "#                       nn.LogSoftmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.layer4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # reshape the images\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.log_softmax(self.layer4(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNetwork(\n",
       "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss:  477.8334218710661\n",
      "Running loss:  368.0196294337511\n",
      "Running loss:  335.19797655195\n",
      "Running loss:  310.2110946998\n",
      "Running loss:  298.86272832751274\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Running loss: \", running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 5\n",
    "# for e in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for images, labels in trainloader:\n",
    "#         images.resize_(64,784)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#     else:\n",
    "#         print(\"Running loss: \", running_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
